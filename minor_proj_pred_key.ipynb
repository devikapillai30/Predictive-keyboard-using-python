{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-0MoWcZVCE"
      },
      "source": [
        "#Importing necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "import pickle\n",
        "import heapq"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjVEMAmF8bPd"
      },
      "source": [
        "**Dataset Information**\n",
        "\n",
        "We have chosen 'The Adventures of Sherlock Holmes' by Sir Arthur Conan Doyle as our primary dataset.\n",
        "\n",
        "\n",
        "'SHERLOCK.txt', the text file from which we are extracting words, contains the entire transcript of the novel in simple text for without formatting.\n",
        "\n",
        "\n",
        " Datasets like these are beneficial for testing text prediction software since they don't include any slang, slurred words or shorthand that may throw off the Neural Network framework. The use of British English also ensures minimal grammatical error possibility as it is a widely recognized writing system across the world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KjcP-k6ZVqA",
        "outputId": "4bcffa3b-718c-4455-d05c-d76e6d06a6f0"
      },
      "source": [
        "#Loading the dataset\n",
        "\n",
        "path = 'SHERLOCK.txt'\n",
        "text = open(path).read().lower() #Reading dataset and converting to lowercase\n",
        "print('Text length:', len(text)) #Text length (including spaces)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text length: 581889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ds9hT9Z0is",
        "outputId": "8413dbbe-0752-467b-f3c7-db11dac24397"
      },
      "source": [
        "#Split the dataset into each word without the presence of special characters\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+') #Reading word characters and storing in an array\n",
        "words = tokenizer.tokenize(text)    #Splitting and storing as list\n",
        "print(words[:5])                     #Printing word list"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['project', 'gutenberg', 's', 'the', 'adventures']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwZksd3qjdl9"
      },
      "source": [
        "unique_words = np.unique(words)                                        #Finds unique elements from our words list\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))   #Running a for loop to create dictionary with words assigned to index values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V4oZSxmVUVN",
        "outputId": "22b36e01-4bf7-4018-8cb2-c39b65998d7f"
      },
      "source": [
        "WORD_LENGTH = 5                                     #No. of previous words taken into consideration\n",
        "prev_words = []                                     #List containing previous words (according to WORD_LENGTH)\n",
        "next_words = []                                     #List containing next word\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "    prev_words.append(words[i:i + WORD_LENGTH])     #Appending previous words in each iteration to prev_words list\n",
        "    next_words.append(words[i + WORD_LENGTH])       #Appending next words in each iteration to next_words list\n",
        "print(prev_words[0])\n",
        "print(next_words[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['project', 'gutenberg', 's', 'the', 'adventures']\n",
            "of\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad62gm50poHt"
      },
      "source": [
        "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)         #Zero array for prev_words with boolean datatype\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)                      #Zero array for next_words with boolean datatype\n",
        "for i, each_words in enumerate(prev_words):\n",
        "    for j, each_word in enumerate(each_words):\n",
        "        X[i, j, unique_word_index[each_word]] = 1                                   #Checking whether value corresponds to 'True' for X\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1                                      #Checking whether value corresponds to 'True' for Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tvN6nAfpsKt",
        "outputId": "245b9326-cf68-4dbf-ce3d-296d804bb990"
      },
      "source": [
        "print(X[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False ... False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22I406Sau1RK"
      },
      "source": [
        "**Building the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1d7J_xWm_TH"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))  #LSTM utilises 128 neurons\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvLTF65Cu5n_"
      },
      "source": [
        "**Training & model creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNN165ZAnYSQ",
        "outputId": "050ebef8-0e94-4d36-825d-bc6f0aadb674"
      },
      "source": [
        "optimizer = RMSprop(lr=0.01)                                                                       #Root Mean Square of error with learning rate = 0.01\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])          #Specifying the training configuration\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history   #Applying the training configuration and creating our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "811/811 [==============================] - 209s 255ms/step - loss: 6.3373 - accuracy: 0.0851 - val_loss: 7.0699 - val_accuracy: 0.1016\n",
            "Epoch 2/2\n",
            "811/811 [==============================] - 206s 254ms/step - loss: 5.6577 - accuracy: 0.1442 - val_loss: 7.9358 - val_accuracy: 0.1064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7jee7O8CqZB"
      },
      "source": [
        "**Loading the model for evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI8tuKobpnle"
      },
      "source": [
        "#Saving our trained model for future use\n",
        "model.save('keras_next_word_model.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
        "model = load_model('keras_next_word_model.h5')\n",
        "history = pickle.load(open(\"history.p\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmlZstaLH5R2",
        "outputId": "2c3825dd-4db7-475d-ae95-dc8b606f32a7"
      },
      "source": [
        "#Model characteristics evaluation\n",
        "history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.10810628533363342, 0.1470426619052887],\n",
              " 'loss': [6.00450325012207, 5.780788421630859],\n",
              " 'val_accuracy': [0.10161112993955612, 0.10637129098176956],\n",
              " 'val_loss': [7.069894313812256, 7.935789108276367]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk04rUEsEuDW"
      },
      "source": [
        "**Setting up prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZITVdk9sExJH",
        "outputId": "47471116-1cb9-4991-9ab7-c63d65f89dc5"
      },
      "source": [
        "#Creating a sample vector with zeros\n",
        "def prepare_input(text):\n",
        "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))       #New array with zeros equal to length of unique_words\n",
        "    for t, word in enumerate(text.split()):\n",
        "        print(word)                                         #Printing each word in input text\n",
        "        x[0, t, unique_word_index[word]] = 1                #Assigning value of 1 in zero array to all words in input text\n",
        "    return x\n",
        "\n",
        "prepare_input(\"It is not a lack\".lower())                   #Calling our new sample vector with input text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it\n",
            "is\n",
            "not\n",
            "a\n",
            "lack\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TscNNpFwk0M6"
      },
      "source": [
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTQaiKN1k01x"
      },
      "source": [
        "def predict_completions(text, n=3):\n",
        "    if text == \"\":\n",
        "        return(\"0\")\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [unique_words[idx] for idx in next_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSfLFeTbOIv3"
      },
      "source": [
        "**Text Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP38_kl1k9RR",
        "outputId": "eb3d1d80-d292-4850-cd89-01156526d93e"
      },
      "source": [
        "#Sentence 1\n",
        "\n",
        "q=input(\"Enter correct sentence: \")\n",
        "#q =  \"Your life will never be the same again\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: Your life will never be the same again\n",
            "correct sentence:  Your life will never be the same again\n",
            "Sequence:  your life will never be\n",
            "your\n",
            "life\n",
            "will\n",
            "never\n",
            "be\n",
            "next possible words:  ['a', 'the', 'of', 'so', 'very']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VnmmBTaOl5B",
        "outputId": "8bcea79d-81d0-4a38-9c7e-adba0c76f806"
      },
      "source": [
        "#Sentence 2\n",
        "\n",
        "q=input(\"Enter correct sentence: \")\n",
        "#q =  \"As I glanced at the\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: As I glanced at the\n",
            "correct sentence:  As I glanced at the\n",
            "Sequence:  as i glanced at the\n",
            "as\n",
            "i\n",
            "glanced\n",
            "at\n",
            "the\n",
            "next possible words:  ['door', 'time', 'and', 'house', 'corner']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUCWNxlxPkjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f86e466-1d63-4871-d04a-90643cd8931d"
      },
      "source": [
        "#Sentence 3\n",
        "\n",
        "q=input(\"Enter correct sentence: \")\n",
        "#q =  \"What could be the reason of his overpowering terror\"\n",
        "print(\"correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "print(\"Sequence: \",seq)\n",
        "print(\"next possible words: \", predict_completions(seq, 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: What could be the reason of his overpowering terror\n",
            "correct sentence:  What could be the reason of his overpowering terror\n",
            "Sequence:  what could be the reason\n",
            "what\n",
            "could\n",
            "be\n",
            "the\n",
            "reason\n",
            "next possible words:  ['of', 'to', 'that', 'i', 'and']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJcSdYKhWihb"
      },
      "source": [
        "**Creating a Function for Text Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEBg1hNmR8rc"
      },
      "source": [
        "def text_pred():\n",
        "  q=input(\"Enter correct sentence: \")\n",
        "  print(\"Correct Sentence: \",q)\n",
        "  seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "  print(\"Sequence: \",seq)\n",
        "  print(\"Next Possible Words: \", predict_completions(seq, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap8elLglXIA4",
        "outputId": "1ecc6a1a-cb34-456b-bbfd-e92c57784e9b"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: Over last few years I\n",
            "Correct Sentence:  Over last few years I\n",
            "Sequence:  over last few years i\n",
            "over\n",
            "last\n",
            "few\n",
            "years\n",
            "i\n",
            "Next Possible Words:  ['have', 'had', 'was', 'am', 'found']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBP_F0B4aZye",
        "outputId": "735cac90-c2ad-4e9b-bc0e-a6f69358b0ff"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: Over last few years I\n",
            "Correct Sentence:  Over last few years I\n",
            "Sequence:  over last few years i\n",
            "over\n",
            "last\n",
            "few\n",
            "years\n",
            "i\n",
            "Next Possible Words:  ['had', 'have', 'was', 'could', 'think']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhKhPmWsshPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d59dca-5406-4bc4-9dfd-0a7549f0eba9"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: I knew little of my\n",
            "Correct Sentence:  I knew little of my\n",
            "Sequence:  i knew little of my\n",
            "i\n",
            "knew\n",
            "little\n",
            "of\n",
            "my\n",
            "Next Possible Words:  ['own', 'that', 'mind', 'room', 'house']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk3X1CWUTST0",
        "outputId": "fb1f741b-9151-4d92-b918-2b0f73421090"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: I should have thought a\n",
            "Correct Sentence:  I should have thought a\n",
            "Sequence:  i should have thought a\n",
            "i\n",
            "should\n",
            "have\n",
            "thought\n",
            "a\n",
            "Next Possible Words:  ['to', 'very', 'little', 'of', 'in']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiUywWG6TcdT",
        "outputId": "27e2727f-c673-47ff-dc0b-d1f9297b8b5c"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: How do I know that\n",
            "Correct Sentence:  How do I know that\n",
            "Sequence:  how do i know that\n",
            "how\n",
            "do\n",
            "i\n",
            "know\n",
            "that\n",
            "Next Possible Words:  ['i', 'it', 'he', 'you', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KF1FJywTpcW",
        "outputId": "d75c5202-5f9e-4b68-a348-7e09e9eb0641"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: my wife has given her\n",
            "Correct Sentence:  my wife has given her\n",
            "Sequence:  my wife has given her\n",
            "my\n",
            "wife\n",
            "has\n",
            "given\n",
            "her\n",
            "Next Possible Words:  ['to', 'the', 'a', 'his', 'her']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w031uW4cT6Hd",
        "outputId": "513453f1-ca73-4f08-ebd8-adb286dfd916"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: He chuckled to himself and\n",
            "Correct Sentence:  He chuckled to himself and\n",
            "Sequence:  he chuckled to himself and\n",
            "he\n",
            "chuckled\n",
            "to\n",
            "himself\n",
            "and\n",
            "Next Possible Words:  ['i', 'a', 'he', 'his', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiBDg0_nUWX8",
        "outputId": "2c28759f-3807-494b-d4f9-453e73cc7bcd"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: Obviously they have been caused\n",
            "Correct Sentence:  Obviously they have been caused\n",
            "Sequence:  obviously they have been caused\n",
            "obviously\n",
            "they\n",
            "have\n",
            "been\n",
            "caused\n",
            "Next Possible Words:  ['to', 'in', 'by', 'upon', 'for']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoeyGiWVV7Rt",
        "outputId": "f6ee8463-f87f-43a2-fd34-646af8a50d5e"
      },
      "source": [
        "text_pred()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter correct sentence: A man entered who could\n",
            "Correct Sentence:  A man entered who could\n",
            "Sequence:  a man entered who could\n",
            "a\n",
            "man\n",
            "entered\n",
            "who\n",
            "could\n",
            "Next Possible Words:  ['not', 'have', 'be', 'see', 'hardly']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}